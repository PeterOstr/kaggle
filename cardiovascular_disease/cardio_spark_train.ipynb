{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:29:59.899040900Z",
     "start_time": "2024-02-07T22:29:53.729927400Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, regexp_replace\n",
    "from pyspark.sql.functions import col, split, explode, regexp_replace\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import lit, col, when\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "import os\n",
    "from pyspark.sql.functions import col, when, lit, isnan\n",
    "from pyspark.sql.functions import lit, nanvl, isnan, when, avg\n",
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import CatBoostEncoder\n",
    "import pickle\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import DoubleType, ArrayType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "sklearn.set_config(transform_output='pandas')\n",
    "from pyspark.sql.functions import array\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession, types as T\n",
    "from pyspark.sql.functions import udf\n",
    "from ast import literal_eval\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "import os\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# from geospark.register import upload_jars\n",
    "# from geospark.register import GeoSparkRegistrator\n",
    "# from geospark.core.SpatialRDD import PolygonRDD, PointRDD\n",
    "# from geospark.core.enums import FileDataSplitter\n",
    "# from geospark.core.enums import IndexType\n",
    "# from geospark.core.geom.envelope import Envelope\n",
    "# from geospark.core.spatialOperator import RangeQuery\n",
    "# from geospark.core.formatMapper.shapefileParser import ShapefileReader\n",
    "# from geospark.sql.types import GeometryType\n",
    "# from geospark.register import sparkJVM\n",
    "# import re\n",
    "# upload_jars()\n",
    "#\n",
    "#\n",
    "#\n",
    "# spark = SparkSession.builder.appName(\"Spark_v1\")    .config(\"spark.default.parallelism\", 176*3) \\\n",
    "#     .config(\"spark.sql.shuffle.partitions\", 176*3) \\\n",
    "#     .config(\"spark.executor.memory\", \"50g\") \\\n",
    "#     .config(\"spark.executor.cores\", \"5\") \\\n",
    "#     .config(\"spark.driver.memory\", \"10g\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"1300g\") \\\n",
    "#     .getOrCreate()\n",
    "import os\n",
    "\n",
    "# setup arguments\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.0'\n",
    "\n",
    "# initialize spark\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, BooleanType\n",
    "\n",
    "\n",
    "ram = 16\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('spark_first_run') \\\n",
    "    .config(\"spark.executor.memory\", f\"{ram}g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", f\"{ram}g\") \\\n",
    "    .config(\"spark.driver.memory\", f\"{ram}g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", f\"{ram}g\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", \"100000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "#    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "\n",
    "#    .config(\"spark.executor.memoryOverhead\", \"10g\") \\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Register Sedona functions to Spark\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import t\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import udf, lit\n",
    "\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import json\n",
    "from pyspark.sql.functions import udf\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import udf, explode\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, FloatType\n",
    "from pyspark.sql.functions import desc\n",
    "from time import sleep\n",
    "from pyspark.sql import Row\n",
    "#from pyspark.sql.functions import min, max\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import split, explode, lower, trim\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, count, col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import monotonically_increasing_id, concat, col, lit, cast\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_list, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import initcap\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "# Get PySpark version\n",
    "print(\"PySpark version:\", pyspark.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:30:19.246750500Z",
     "start_time": "2024-02-07T22:30:19.223752Z"
    }
   },
   "id": "4067a16e11842dca",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      message|\n",
      "+-------------+\n",
      "|Hello, World!|\n",
      "+-------------+\n"
     ]
    }
   ],
   "source": [
    "# # Create a SparkSession\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"HelloWorld\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# Create a DataFrame with a single column named \"message\" and a single row containing the string \"Hello, World!\"\n",
    "data = [(\"Hello, World!\",)]\n",
    "df = spark.createDataFrame(data, [\"message\"])\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:30:37.013881400Z",
     "start_time": "2024-02-07T22:30:24.384133300Z"
    }
   },
   "id": "c5f9f1d10037ef6d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n0        988  22469       1     155    69.0    130     80            2     2   \n1        989  14648       1     163    71.0    110     70            1     1   \n2        990  21901       1     165    70.0    120     80            1     1   \n3        991  14549       2     165    85.0    120     80            1     1   \n4        992  23393       1     155    62.0    120     80            1     1   \n...      ...    ...     ...     ...     ...    ...    ...          ...   ...   \n69296  99993  19240       2     168    76.0    120     80            1     1   \n69297  99995  22601       1     158   126.0    140     90            2     2   \n69298  99996  19066       2     183   105.0    180     90            3     1   \n69299  99998  22431       1     163    72.0    135     80            1     2   \n69300  99999  20540       1     170    72.0    120     80            2     1   \n\n       smoke  alco  active  cardio  \n0          0     0       1       0  \n1          0     0       1       1  \n2          0     0       1       0  \n3          1     1       1       0  \n4          0     0       1       0  \n...      ...   ...     ...     ...  \n69296      1     0       1       0  \n69297      0     0       1       1  \n69298      0     1       0       1  \n69299      0     0       0       1  \n69300      0     0       1       0  \n\n[69301 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>ap_hi</th>\n      <th>ap_lo</th>\n      <th>cholesterol</th>\n      <th>gluc</th>\n      <th>smoke</th>\n      <th>alco</th>\n      <th>active</th>\n      <th>cardio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>988</td>\n      <td>22469</td>\n      <td>1</td>\n      <td>155</td>\n      <td>69.0</td>\n      <td>130</td>\n      <td>80</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>989</td>\n      <td>14648</td>\n      <td>1</td>\n      <td>163</td>\n      <td>71.0</td>\n      <td>110</td>\n      <td>70</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>990</td>\n      <td>21901</td>\n      <td>1</td>\n      <td>165</td>\n      <td>70.0</td>\n      <td>120</td>\n      <td>80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>991</td>\n      <td>14549</td>\n      <td>2</td>\n      <td>165</td>\n      <td>85.0</td>\n      <td>120</td>\n      <td>80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>992</td>\n      <td>23393</td>\n      <td>1</td>\n      <td>155</td>\n      <td>62.0</td>\n      <td>120</td>\n      <td>80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69296</th>\n      <td>99993</td>\n      <td>19240</td>\n      <td>2</td>\n      <td>168</td>\n      <td>76.0</td>\n      <td>120</td>\n      <td>80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>69297</th>\n      <td>99995</td>\n      <td>22601</td>\n      <td>1</td>\n      <td>158</td>\n      <td>126.0</td>\n      <td>140</td>\n      <td>90</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>69298</th>\n      <td>99996</td>\n      <td>19066</td>\n      <td>2</td>\n      <td>183</td>\n      <td>105.0</td>\n      <td>180</td>\n      <td>90</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>69299</th>\n      <td>99998</td>\n      <td>22431</td>\n      <td>1</td>\n      <td>163</td>\n      <td>72.0</td>\n      <td>135</td>\n      <td>80</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>69300</th>\n      <td>99999</td>\n      <td>20540</td>\n      <td>1</td>\n      <td>170</td>\n      <td>72.0</td>\n      <td>120</td>\n      <td>80</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>69301 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv('data/Covid_data.csv')\n",
    "data = pd.read_csv('data/cardio_train.csv', sep=';')\n",
    "\n",
    "# data[data['DATE_DIED']==9999-99-99]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:31:20.426703600Z",
     "start_time": "2024-02-07T22:31:20.335704600Z"
    }
   },
   "id": "b3f7080cef31dd04",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- height: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      " |-- ap_hi: string (nullable = true)\n",
      " |-- ap_lo: string (nullable = true)\n",
      " |-- cholesterol: string (nullable = true)\n",
      " |-- gluc: string (nullable = true)\n",
      " |-- smoke: string (nullable = true)\n",
      " |-- alco: string (nullable = true)\n",
      " |-- active: string (nullable = true)\n",
      " |-- cardio: string (nullable = true)\n",
      "\n",
      "+----+-----+------+------+------+-----+-----+-----------+----+-----+----+------+------+\n",
      "|  id|  age|gender|height|weight|ap_hi|ap_lo|cholesterol|gluc|smoke|alco|active|cardio|\n",
      "+----+-----+------+------+------+-----+-----+-----------+----+-----+----+------+------+\n",
      "| 988|22469|     1|   155|  69.0|  130|   80|          2|   2|    0|   0|     1|     0|\n",
      "| 989|14648|     1|   163|  71.0|  110|   70|          1|   1|    0|   0|     1|     1|\n",
      "| 990|21901|     1|   165|  70.0|  120|   80|          1|   1|    0|   0|     1|     0|\n",
      "| 991|14549|     2|   165|  85.0|  120|   80|          1|   1|    1|   1|     1|     0|\n",
      "| 992|23393|     1|   155|  62.0|  120|   80|          1|   1|    0|   0|     1|     0|\n",
      "| 995|21143|     1|   164|  61.0|  100|   70|          1|   1|    0|   0|     1|     0|\n",
      "| 996|18085|     1|   162|  72.0|  100|   70|          1|   1|    0|   0|     1|     0|\n",
      "| 997|22547|     1|   161|  93.0|  140|   90|          2|   1|    0|   0|     1|     1|\n",
      "| 999|21250|     1|   157|  68.0|  110|   80|          1|   1|    0|   0|     1|     0|\n",
      "|1000|22446|     1|   158|  65.0|  140|   90|          3|   1|    0|   0|     1|     1|\n",
      "|1001|16621|     1|   153|  57.0|  120|   80|          3|   2|    0|   0|     1|     1|\n",
      "|1002|20442|     2|   169|  82.0|  130|   90|          1|   1|    0|   0|     1|     1|\n",
      "|1003|23168|     2|   150|  56.0|  130|   80|          2|   1|    0|   0|     1|     1|\n",
      "|1004|22598|     1|   176|  72.0|  130|   90|          1|   3|    0|   0|     1|     1|\n",
      "|1006|20317|     1|   154|  85.0|  160|  100|          3|   1|    0|   0|     1|     1|\n",
      "|1008|23558|     1|   159|  60.0|  120|   80|          1|   1|    0|   0|     1|     1|\n",
      "|1010|20219|     2|   146|  45.0|  120|   80|          1|   1|    0|   0|     1|     0|\n",
      "|1011|19559|     1|   165|  90.0|  140|   90|          1|   1|    0|   0|     1|     1|\n",
      "|1013|20006|     2|   167|  65.0|  120|   80|          1|   1|    0|   0|     0|     0|\n",
      "|1014|19054|     1|   154|  70.0|  110|   70|          1|   1|    0|   0|     1|     0|\n",
      "+----+-----+------+------+------+-----+-----+-----------+----+-----+----+------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file into table\n",
    "df = spark.read.option(\"header\",True) \\\n",
    "    .csv('data/cardio_train.csv', sep=';')\n",
    "df.printSchema()\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:32:35.276082700Z",
     "start_time": "2024-02-07T22:32:34.415081600Z"
    }
   },
   "id": "1eff60d79b99dd2e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('DATA')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:32:47.669762300Z",
     "start_time": "2024-02-07T22:32:47.580760300Z"
    }
   },
   "id": "88c143f2d3246e3d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|  AGE|\n",
      "+-----+\n",
      "|22469|\n",
      "|14648|\n",
      "|21901|\n",
      "|14549|\n",
      "|23393|\n",
      "|21143|\n",
      "|18085|\n",
      "|22547|\n",
      "|21250|\n",
      "|22446|\n",
      "|16621|\n",
      "|20442|\n",
      "|23168|\n",
      "|22598|\n",
      "|20317|\n",
      "|23558|\n",
      "|20219|\n",
      "|19559|\n",
      "|20006|\n",
      "|19054|\n",
      "|23407|\n",
      "|22833|\n",
      "|20465|\n",
      "|21737|\n",
      "|19881|\n",
      "+-----+\n"
     ]
    }
   ],
   "source": [
    "# SQL Select query\n",
    "spark.sql('''\n",
    "    \n",
    "    SELECT \n",
    "        AGE\n",
    "    FROM DATA\n",
    "    \n",
    "''') \\\n",
    "    .show(25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T22:33:50.948605700Z",
     "start_time": "2024-02-07T22:33:50.778604300Z"
    }
   },
   "id": "bc8a9f2255013989",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
